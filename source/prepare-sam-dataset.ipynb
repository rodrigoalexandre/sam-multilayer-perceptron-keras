{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58dffa5e",
   "metadata": {},
   "source": [
    "#### Convert the original dataset files (extension .mat) to CSV format.\n",
    " - The dataset comprises 480 .mat files (MATLAB files)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd8d21d",
   "metadata": {},
   "source": [
    "#### Import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0a0dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc6a98d",
   "metadata": {},
   "source": [
    "#### Function that returns the scale (stress level) assigned by a given individual to perform a given task. \n",
    "- The first parameter is the dataframe with the spreadsheet with all the classifications assigned by the individuals. \n",
    "- The second parameter is the name of the file being processed. Each file has the records of the execution of a certain task, so all samples of a certain file have the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07628254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScale(data_frame, file_name) :\n",
    "\n",
    "    file_itens = file_name.split('_')\n",
    "    task_desc = \"\"\n",
    "    sub_number = \"\"\n",
    "    try_number = \"\"\n",
    "\n",
    "    if (file_itens[0] == \"Mirror\") :\n",
    "        task_desc = file_itens[0]\n",
    "        sub_number = file_itens[3]\n",
    "        try_number = file_itens[4].split('.')[0]\n",
    "    else :\n",
    "        task_desc = file_itens[0]\n",
    "        sub_number = file_itens[2]\n",
    "        try_number = file_itens[3].split('.')[0]\n",
    "\n",
    "    line_index = data_frame[data_frame['Subject'] == int(sub_number)].index[0]\n",
    "    column_name = \"\"\n",
    "\n",
    "    if (task_desc == \"Arithmetic\") :\n",
    "        column_name = \"Maths\" + try_number[-1]\n",
    "    elif (task_desc == \"Mirror\") :\n",
    "        column_name = \"Symmetry\" + try_number[-1]\n",
    "    elif (task_desc == \"Stroop\") :\n",
    "        column_name = \"Stroop\" + try_number[-1]\n",
    "    else :\n",
    "        return 0\n",
    "\n",
    "    return data_frame.iloc[line_index][column_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94588a",
   "metadata": {},
   "source": [
    "#### Function that converts the list of .mat files into CSV format.\n",
    "- The result is grouped into a single .CSV file.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd82e6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_files(filesList):\n",
    "\n",
    "    print(\"Start function join_files.\")\n",
    "\n",
    "    all_features = {}\n",
    "    for index in range(0, 32):\n",
    "        all_features[index] = np.empty(0)\n",
    "\n",
    "    label_index = index+1\n",
    "    all_features[label_index] = np.empty(0, dtype=int)\n",
    "\n",
    "    all_scales = pd.read_excel('../dataset/scales.xls')\n",
    "\n",
    "    for fileName in filesList:\n",
    "        fileContent = scipy.io.loadmat('../dataset/' + fileName) \n",
    "        for x in fileContent:\n",
    "            # Consider only the dictionary element numpy.ndarray\n",
    "            if isinstance(fileContent[x], np.ndarray):\n",
    "                features_count = 0\n",
    "                for y in fileContent[x]:\n",
    "                    all_features[features_count] = np.append(all_features[features_count], y)\n",
    "                    features_count += 1\n",
    "                for y in range(0, len(fileContent[x][0])):\n",
    "                    label_value = getScale(all_scales, fileName)\n",
    "                    all_features[features_count] = np.append(all_features[features_count], label_value)\n",
    "\n",
    "    print(\"Start writing CSV file.\")\n",
    "    df = pd.DataFrame.from_dict(all_features)\n",
    "  \n",
    "    df.rename(columns={0: 'CZ', 1: 'FZ', 2: 'Fp1', 3: 'F7', 4: 'F3', 5: 'FC1', 6: 'C3', 7: 'FC5', 8: 'FT9', 9: 'T7',\n",
    "                       10: 'CP5', 11: 'CP1', 12: 'P3', 13: 'P7', 14: 'PO9', 15: 'O1', 16: 'PZ', 17: 'OZ', 18: 'O2',\n",
    "                       19: 'PO10', 20: 'P8', 21: 'P4', 22: 'CP2', 23: 'CP6', 24: 'T8', 25: 'FT10', 26: 'FC6',\n",
    "                       27: 'C4', 28: 'FC2', 29: 'F4', 30: 'F8', 31: 'Fp2', 32: 'Scale'}, inplace = True)\n",
    "\n",
    "    df.to_csv('../dataset/original-sam-dataset.csv', index = False,  sep='|')\n",
    "    print(\"Finish writing CSV file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f72c00",
   "metadata": {},
   "source": [
    "#### Generate the list with the names of the .mat files to be converted to CSV and call the conversion function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e1d9bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start function join_files.\n",
      "Start writing CSV file.\n",
      "Finish writing CSV file.\n"
     ]
    }
   ],
   "source": [
    "filesList = []\n",
    "\n",
    "tasksList = [\"Arithmetic\", \"Mirror_image\", \"Relax\", \"Stroop\"]\n",
    "\n",
    "for task in tasksList:\n",
    "    for subject in range(0, 40):\n",
    "        for trials in range(0, 3):\n",
    "            filesList.append(task + \"_sub_\" + str(subject + 1) + \"_trial\" + str(trials + 1) + \".mat\")\n",
    "\n",
    "join_files(filesList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
